{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data_rows_list = [] \n",
    "    \n",
    "for f in file_path_list:\n",
    "\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile:  \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "               \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster and establishing connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "        WITH REPLICATION = \n",
    "        { 'class' : 'SimpleStrategy', 'replication_factor' : 1} \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 1: \n",
    "##### 1. The requirement is to query artist, song_title and song's length based on session_id and itemInSession so we created a composite primary key with partition key as sessionId and clustering column as itemInSession. \n",
    "##### 2. The table description is as follows:\n",
    "               TABLE NAME: song_in_session \n",
    "                   session_id int\n",
    "                   itemInSession int\n",
    "                   artist_name text\n",
    "                   song_title text\n",
    "                   song_length decimal\n",
    "                   PRIMARY KEY(session_id, itemInSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"CREATE TABLE IF NOT EXISTS song_in_session (\n",
    "                       session_id int, itemInSession int, artist_name text, song_title text, song_length decimal,\n",
    "                       PRIMARY KEY(session_id, itemInSession))\"\"\")\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The following code reads the csv file and inserts the data into 'song_in_session' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_in_session(session_id, itemInSession, artist_name, song_title, song_length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[-3]), int(line[3]), line[0], line[-2], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist_name, song_title, song_length FROM song_in_session \\\n",
    "         WHERE session_id = 338 AND itemInSession = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row.artist_name, row.song_title, row.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 2: \n",
    "##### 1. The requirement is to query artist, song_title sorted by itemInSession, user's first_name and last_name based on user_id and session_id so we created a composite primary key with partition key as user_id and sessionId and clustering column as itemInSession. \n",
    "##### 2. The reason to use user_id and session_id both as the partition key and not just user_id is because we want session_id's that belong to the same user will be put on different tables which can result in performance issues if the volume of the data increases.\n",
    "##### 3. Finally we use itemInSession as the clustering column because we want data to be sorted based on this column.\n",
    "##### 4. The table description is as follows:\n",
    "               TABLE NAME: user_session_details \n",
    "                   user_id int\n",
    "                   session_id int\n",
    "                   artist_name text\n",
    "                   song_title text\n",
    "                   itemInSession int\n",
    "                   first_name text\n",
    "                   last_name text\n",
    "                   PRIMARY KEY((user_id, session_id), itemInSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE TABLE user_session_details(user_id int, session_id int,artist_name text, song_title text, \n",
    "                     itemInSession int, first_name text, last_name text,\n",
    "                     PRIMARY KEY((user_id, session_id), itemInSession))\"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The following code reads the csv file and inserts the data into 'song_in_session' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_session_details(user_id, session_id, artist_name, song_title, itemInSession, first_name, last_name)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[-1]), int(line[-3]), line[0], line[-2], int(line[3]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "1 Three Drives Greece 2000 Sylvie Cruz\n",
      "2 Sebastien Tellier Kilometer Sylvie Cruz\n",
      "3 Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT itemInSession, artist_name, song_title, first_name, last_name FROM user_session_details WHERE user_id=10 AND session_id=182\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "for row in rows:\n",
    "    print(row.iteminsession, row.artist_name, row.song_title, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 3: \n",
    "##### 1. The requirement is to query every user's first_name and last_name based on song_title so we created a composite primary key with partition key as song_title and clustering column as user_id.\n",
    "##### 2. The reason to select user_id as clustering column is that multiple users are likely to listen to a common song. If clustering column is not added only 1 entry for a song_title is inserted in the database. We want to preserve the user information to display all the users listening to a particular song.\n",
    "##### 3. user_id is used to uniquely identify a user, so we add clustering column as user_id.\n",
    "##### 4. The table description is as follows:\n",
    "               TABLE NAME: user_songs\n",
    "                   song_title text\n",
    "                   user_id int\n",
    "                   first_name text\n",
    "                   last_name text\n",
    "                   PRIMARY KEY(song_title, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE user_songs(song_title text, user_id int, first_name text, last_name text, \n",
    "                 PRIMARY KEY(song_title, user_id))\"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The following code reads the csv file and inserts the data into 'song_in_session' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_songs(user_id, song_title, first_name, last_name)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[-1]), line[-2], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT first_name, last_name FROM user_songs WHERE song_title='All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row.first_name,row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"DROP TABLE IF EXISTS song_in_session\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS user_session_details\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS user_songs\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
